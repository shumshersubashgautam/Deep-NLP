{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc/MVQ+/BT67ScB7hftMpp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shumshersubashgautam/Deep-NLP/blob/main/NLP_EDA_in_PySpark_%2B_ML_pipeline_LR_NB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "T4o8g9ZjV5mF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH4uZfJHXiNf",
        "outputId": "482151c9-84ac-4126-c286-43d6bd237e7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 74 May  1 08:13 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "rjZwnjgOX9gg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "FLaYjGheX_dR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "FjQFoPCPYCnC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alE9uT9xYEsz",
        "outputId": "6c1e9fad-6754-4b16-bf51-f3a263b31061"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d samdeeplearning/deepnlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtgGO1fWYdKU",
        "outputId": "c3e19271-5c50-4a7c-cdae-dddf3e85553c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deepnlp.zip to /content\n",
            "\r  0% 0.00/234k [00:00<?, ?B/s]\n",
            "\r100% 234k/234k [00:00<00:00, 128MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/deepnlp.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFQPIyTyYkj6",
        "outputId": "b9cadace-e3a1-4502-970a-7c06dff06a5e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/deepnlp.zip\n",
            "  inflating: Sheet_1.csv             \n",
            "  inflating: Sheet_2.csv             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZxI5UV6i8sb",
        "outputId": "efa1ef16-9f91-49d6-e725-2a037ec5483e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=ada2ca15cbf3b889a58a5091c1ecd7afb3487dfa7f22bc97fec5c69160558132\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c8yNyL1jNAH",
        "outputId": "d410583d-4590-4422-952e-0699634f0285"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "SPARK = SparkSession.builder.appName(\"ProyectoNLPpysparkEDA\").getOrCreate()"
      ],
      "metadata": {
        "id": "_cCfjnKFjS7c"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import (Tokenizer, RegexTokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer,NGram)"
      ],
      "metadata": {
        "id": "pu8k-fiQjhHx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,udf, length"
      ],
      "metadata": {
        "id": "IOkerPnUjmLx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType"
      ],
      "metadata": {
        "id": "SS25MNFzjoSV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = SPARK.read.csv(\"/content/Sheet_1.csv\",\n",
        "                   inferSchema=True, sep=\",\",header=True)"
      ],
      "metadata": {
        "id": "U9Z3KHL9jrOW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()\n",
        "## Drop the columns without data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTdm5y0fjv5Q",
        "outputId": "41f1697a-556f-4b02-eb5b-2542ccff3b10"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------------+----+----+----+----+----+\n",
            "|response_id|      class|       response_text| _c3| _c4| _c5| _c6| _c7|\n",
            "+-----------+-----------+--------------------+----+----+----+----+----+\n",
            "| response_1|not_flagged|I try and avoid t...|null|null|null|null|null|\n",
            "| response_2|    flagged|Had a friend open...|null|null|null|null|null|\n",
            "| response_3|    flagged|I saved a girl fr...|null|null|null|null|null|\n",
            "| response_4|not_flagged|i cant think of o...|null|null|null|null|null|\n",
            "| response_5|not_flagged|\"Only really one ...|    |null|null|null|null|\n",
            "| response_6|not_flagged|a couple of years...|null|null|null|null|null|\n",
            "| response_7|    flagged|Roommate when he ...|null|null|null|null|null|\n",
            "| response_8|    flagged|i've had a couple...|null|null|null|null|null|\n",
            "| response_9|not_flagged|Listened to someo...|null|null|null|null|null|\n",
            "|response_10|    flagged|I will always lis...|null|null|null|null|null|\n",
            "|response_11|not_flagged|Took a week off w...|null|null|null|null|null|\n",
            "|response_12|    flagged|On the memorial a...|null|null|null|null|null|\n",
            "|response_13|not_flagged|Anxious girlfrien...|null|null|null|null|null|\n",
            "|response_14|not_flagged|               Never|null|null|null|null|null|\n",
            "|response_15|not_flagged|        You as a mom|null|null|null|null|null|\n",
            "|response_16|    flagged|ex gf was a cutte...|null|null|null|null|null|\n",
            "|response_17|not_flagged|I have helped adv...|null|null|null|null|null|\n",
            "|response_18|not_flagged|I've helped frien...|null|null|null|null|null|\n",
            "|response_19|not_flagged|A friend that is ...|null|null|null|null|null|\n",
            "|response_20|not_flagged|expressing concer...|null|null|null|null|null|\n",
            "+-----------+-----------+--------------------+----+----+----+----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select(\"response_id\",\"class\",\"response_text\")\n",
        "## Select only the columns with data"
      ],
      "metadata": {
        "id": "Qaszxfbsjy-9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's see the data distribution\n",
        "## Flagged messages are half the not_flagged\n",
        "\n",
        "df.groupBy().pivot(\"class\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmGkT4xoj146",
        "outputId": "4fcb55cc-bf2b-45a5-b6c5-1d54efbb7042"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|flagged|not_flagged|\n",
            "+-------+-----------+\n",
            "|     25|         55|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df =  df.withColumn(\"length\", length(df[\"response_text\"]))"
      ],
      "metadata": {
        "id": "aKwzRXflj5qb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"class\").mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgXUA2VZj8lZ",
        "outputId": "5121fc95-825f-465a-ba75-75a377bbd4d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|      class|       avg(length)|\n",
            "+-----------+------------------+\n",
            "|    flagged|            261.64|\n",
            "|not_flagged|117.81818181818181|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fignFAaDj-hs",
        "outputId": "11f73756-452d-489a-8dd3-aef7cc7dfb60"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------------+------+\n",
            "|response_id|      class|       response_text|length|\n",
            "+-----------+-----------+--------------------+------+\n",
            "| response_1|not_flagged|I try and avoid t...|    37|\n",
            "| response_2|    flagged|Had a friend open...|   122|\n",
            "| response_3|    flagged|I saved a girl fr...|   130|\n",
            "+-----------+-----------+--------------------+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"response_text\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuPvtbwskAps",
        "outputId": "4068d549-1d9d-44db-e419-09f9fdd486aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|response_text                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|I try and avoid this sort of conflict                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|Had a friend open up to me about his mental addiction to weed and how it was taking over his life and making him depressed                                                                                                                                                                                                                                                                          |\n",
            "|I saved a girl from suicide once. She was going to swallow a bunch of pills and I talked her out of it in a very calm, loving way.                                                                                                                                                                                                                                                                  |\n",
            "|i cant think of one really...i think i may have indirectly                                                                                                                                                                                                                                                                                                                                          |\n",
            "|\"Only really one friend who doesn't fit into the any of the above categories. Her therapist calls it spiraling.\"\" Anyway she pretty much calls me any time she is frustrated by something with  her boyfriend to ask me if it's logical or not. Before they would just fight and he would call her crazy. Now she asks me if it's ok he didn't say \"\"please\"\" when he said  \"\"hand me the remote.\"\"\"|\n",
            "|a couple of years ago my friends was going to switch school because of low self esteem too. I helped him overcome that shit too                                                                                                                                                                                                                                                                     |\n",
            "|Roommate when he was going through death and loss of a gf. Did anything to get him out of his bedroom.                                                                                                                                                                                                                                                                                              |\n",
            "|i've had a couple of friends (you could say more than friends) with quite severe depression/ emotional problems. i helped for a while but eventually both relationships started to suffer as a result of both our personal problems                                                                                                                                                                 |\n",
            "|Listened to someone talk about relationship troubles. Offered some advice from personal experience.                                                                                                                                                                                                                                                                                                 |\n",
            "|I will always listen. I comforted my sister when she lost her virgity the same night she walked in on her boyfriend cutting himself, and then our parents found out she threw a house part. Simply bring supportive was my focus.                                                                                                                                                                   |\n",
            "|Took a week off work, packed up the car and picked up a friend who was on the verge of losing it and went camping/surfing for a week. His parents were a big part of the problem and being away from them and others and physical activity every day for a week. but more just being around helped i feel.                                                                                          |\n",
            "|On the memorial anniversary of my friends father I was with him to give support and remind him that he's not alone.                                                                                                                                                                                                                                                                                 |\n",
            "|Anxious girlfriend always needs my help                                                                                                                                                                                                                                                                                                                                                             |\n",
            "|Never                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|You as a mom                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "|ex gf was a cutter/suicidal, got her out of her own issues while slowly dying inside.                                                                                                                                                                                                                                                                                                               |\n",
            "|I have helped advise friends who have faced circumstances similar to mine                                                                                                                                                                                                                                                                                                                           |\n",
            "|I've helped friends out before                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|A friend that is a girl and just talk to her tryin to make her feel better                                                                                                                                                                                                                                                                                                                          |\n",
            "|expressing concern and openness to friends when they are dealing with troubles. letting them know they can fell open for dialog.                                                                                                                                                                                                                                                                    |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## To count words and stopwords we need to tokenize first the messages\n",
        "tokenizer = Tokenizer(inputCol=\"response_text\" ,outputCol=\"token_text\") \n",
        "tokenized = tokenizer.transform(df)"
      ],
      "metadata": {
        "id": "e78FNcoxkChH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2-WK9gbkFk_",
        "outputId": "8c8866a7-43bb-43a7-c575-32e593703589"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------------+------+--------------------+\n",
            "|response_id|      class|       response_text|length|          token_text|\n",
            "+-----------+-----------+--------------------+------+--------------------+\n",
            "| response_1|not_flagged|I try and avoid t...|    37|[i, try, and, avo...|\n",
            "| response_2|    flagged|Had a friend open...|   122|[had, a, friend, ...|\n",
            "| response_3|    flagged|I saved a girl fr...|   130|[i, saved, a, gir...|\n",
            "+-----------+-----------+--------------------+------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, count, explode\n",
        "\n",
        "Q_of_words = tokenized.select(\"*\", explode(\"token_text\").alias(\"exploded\")).groupBy(\"class\", \"response_text\",\"token_text\",\"length\").agg(count(\"exploded\").alias(\"Words\"))"
      ],
      "metadata": {
        "id": "JD48HGEEkHpc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q_of_words.show(3)\n",
        "## Quiantity of words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_dWQEhWkKRT",
        "outputId": "898ff739-7fca-4286-c017-e3e947d81706"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+--------------------+------+-----+\n",
            "|      class|       response_text|          token_text|length|Words|\n",
            "+-----------+--------------------+--------------------+------+-----+\n",
            "|not_flagged|I have helped adv...|[i, have, helped,...|    73|   12|\n",
            "|not_flagged|Listened to someo...|[listened, to, so...|    99|   13|\n",
            "|    flagged|One of my best fr...|[one, of, my, bes...|   284|   59|\n",
            "+-----------+--------------------+--------------------+------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SWS = StopWordsRemover(inputCol=\"token_text\" ,outputCol=\"SWS_\") \n",
        "swsd = SWS.transform(Q_of_words)"
      ],
      "metadata": {
        "id": "OnUkpLfZkMXW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swsd.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz9jyh9SkOji",
        "outputId": "000cb2f2-2c9d-4b27-d19d-9c5fc4ca316a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+--------------------+------+-----+--------------------+\n",
            "|      class|       response_text|          token_text|length|Words|                SWS_|\n",
            "+-----------+--------------------+--------------------+------+-----+--------------------+\n",
            "|not_flagged|I have helped adv...|[i, have, helped,...|    73|   12|[helped, advise, ...|\n",
            "|not_flagged|Listened to someo...|[listened, to, so...|    99|   13|[listened, someon...|\n",
            "|    flagged|One of my best fr...|[one, of, my, bes...|   284|   59|[one, best, frien...|\n",
            "+-----------+--------------------+--------------------+------+-----+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_stops = swsd.select(\"*\", explode(\"SWS_\").alias(\"boom\")).groupBy(\"class\",\"response_text\", \"SWS_\",\"Words\",\"length\").agg(count(\"boom\").alias(\"q_stops\"))"
      ],
      "metadata": {
        "id": "1r-hD0GJkQXG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q_stops.show(3)\n",
        "## Quantity of words without StopWords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2DVRMfwkStf",
        "outputId": "7f091431-68ba-4841-9095-e6b018e68296"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+--------------------+-----+------+-------+\n",
            "|      class|       response_text|                SWS_|Words|length|q_stops|\n",
            "+-----------+--------------------+--------------------+-----+------+-------+\n",
            "|    flagged|I've had some fri...|[friends, come, s...|   50|   276|     23|\n",
            "|not_flagged|I've always been ...|[always, good, li...|   60|   312|     28|\n",
            "|    flagged|One of my best fr...|[one, best, frien...|   59|   284|     23|\n",
            "+-----------+--------------------+--------------------+-----+------+-------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_stops.groupBy(\"class\").mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M-uQPD1kUZ9",
        "outputId": "251d1d15-922f-4612-e758-06ca54da346a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+------------------+------------------+\n",
            "|      class|       avg(Words)|       avg(length)|      avg(q_stops)|\n",
            "+-----------+-----------------+------------------+------------------+\n",
            "|    flagged|             50.6|            261.64|              22.8|\n",
            "|not_flagged|22.69090909090909|117.81818181818181|10.545454545454545|\n",
            "+-----------+-----------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_of_words.groupBy(\"class\").mean().show()\n",
        "# Flagged have more words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9yf5SzNkWuL",
        "outputId": "70140dcd-5368-4f7a-ab7e-ed82e55c359f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+-----------------+\n",
            "|      class|       avg(length)|       avg(Words)|\n",
            "+-----------+------------------+-----------------+\n",
            "|    flagged|            261.64|             50.6|\n",
            "|not_flagged|117.81818181818181|22.69090909090909|\n",
            "+-----------+------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## In order to get the Q of stopwords we substract Q_WORDS- Q_STOPWOWRDS\n",
        "df2 = Q_stops.withColumn(\"StopWordsQ\",col(\"Words\")-col(\"q_stops\"))"
      ],
      "metadata": {
        "id": "r2p1tkfWkYWT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8NMuGNCkavp",
        "outputId": "754a6830-2cb3-4616-b726-f002d69c7e90"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+--------------------+-----+------+-------+----------+\n",
            "|      class|       response_text|                SWS_|Words|length|q_stops|StopWordsQ|\n",
            "+-----------+--------------------+--------------------+-----+------+-------+----------+\n",
            "|    flagged|I've had some fri...|[friends, come, s...|   50|   276|     23|        27|\n",
            "|not_flagged|I've always been ...|[always, good, li...|   60|   312|     28|        32|\n",
            "|    flagged|One of my best fr...|[one, best, frien...|   59|   284|     23|        36|\n",
            "+-----------+--------------------+--------------------+-----+------+-------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.groupBy(\"class\").mean().show()\n",
        "## Flagged have more stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saxzZcM-kc7l",
        "outputId": "08fad09d-2634-40c2-c824-0a8be4c719da"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+------------------+------------------+------------------+\n",
            "|      class|       avg(Words)|       avg(length)|      avg(q_stops)|   avg(StopWordsQ)|\n",
            "+-----------+-----------------+------------------+------------------+------------------+\n",
            "|    flagged|             50.6|            261.64|              22.8|              27.8|\n",
            "|not_flagged|22.69090909090909|117.81818181818181|10.545454545454545|12.145454545454545|\n",
            "+-----------+-----------------+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create the variables for the pipeline\n",
        "tokenizer = Tokenizer(inputCol=\"response_text\" ,outputCol=\"token_text\")\n",
        "stop_remove=StopWordsRemover(inputCol=\"token_text\" ,outputCol=\"stop_text\")\n",
        "count_vect=CountVectorizer(inputCol=\"stop_text\" ,outputCol=\"c_vec\")\n",
        "idf=IDF(inputCol=\"c_vec\" ,outputCol=\"tf_idf\")\n",
        "\n",
        "flag_nflag_numeric=StringIndexer(inputCol=\"class\" ,outputCol=\"label\") ### Label Encoder ( 0, 1)"
      ],
      "metadata": {
        "id": "Pm_q8XJCkfNX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "ZlYXJqookh2a"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Choose the features\n",
        "clean_up = VectorAssembler(inputCols=[\"tf_idf\",\"length\",\"StopWordsQ\"],outputCol=\"features\")"
      ],
      "metadata": {
        "id": "RYt9o-lnkjuB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "b3PUaynokmFo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb  = NaiveBayes()\n",
        "lr = LogisticRegression()"
      ],
      "metadata": {
        "id": "yVhOtOeHkoIc"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "BaPI30VNkqHF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the pipeline\n",
        "data_prep_pipe = Pipeline(stages = [flag_nflag_numeric,tokenizer,stop_remove,count_vect,\n",
        "                          idf,clean_up])"
      ],
      "metadata": {
        "id": "tj6JHW9xksLN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner = data_prep_pipe.fit(df2)"
      ],
      "metadata": {
        "id": "P1-7__hWkuAx"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = cleaner.transform(df2)"
      ],
      "metadata": {
        "id": "Xpl2evO0kv96"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = clean_data.select(\"label\",\"features\")"
      ],
      "metadata": {
        "id": "0MLDGWbMkyfz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVZ_1O0Kk0G8",
        "outputId": "b8169a02-bee0-4796-f51e-bca03cdbd163"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  1.0|(661,[0,1,2,9,14,...|\n",
            "|  0.0|(661,[2,3,12,15,1...|\n",
            "|  1.0|(661,[1,4,8,11,14...|\n",
            "|  0.0|(661,[1,3,9,14,17...|\n",
            "+-----+--------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training,test=clean_data.randomSplit([0.7,0.3])"
      ],
      "metadata": {
        "id": "H7xmIuFWk2B3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag_detector = nb.fit(training)"
      ],
      "metadata": {
        "id": "RULy86_Ek32c"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = flag_detector.transform(test)"
      ],
      "metadata": {
        "id": "n-W0bJmYk5Wc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W06NQK2Ck620",
        "outputId": "e1f4574c-f2fa-4cdd-b934-8328bd174c62"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|label|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|  0.0|(661,[0,3,8,36,48...|[-1184.4708210377...|[1.04049506505653...|       1.0|\n",
            "|  0.0|(661,[0,6,19,35,3...|[-193.80609579086...|[0.99994296873365...|       0.0|\n",
            "|  0.0|(661,[0,55,88,544...|[-115.79675779250...|[0.01333346952558...|       1.0|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "acc_eval=MulticlassClassificationEvaluator()"
      ],
      "metadata": {
        "id": "nb_IHpwdk8U_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = acc_eval.evaluate(test_results,{acc_eval.metricName: \"f1\"})"
      ],
      "metadata": {
        "id": "pmuRywPck-QZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu3D_bx-k_4B",
        "outputId": "0611a5a9-36e9-4e53-aaf6-cb74b2580e15"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4839506172839507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator= MulticlassClassificationEvaluator()\n",
        "\n",
        "evaluator.setPredictionCol(\"prediction\")\n",
        "\n",
        "\n",
        "evaluator.evaluate(test_results)\n",
        "\n",
        "\n",
        "evaluator.evaluate(test_results, {evaluator.metricName: \"accuracy\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EfKW7t0lBZY",
        "outputId": "cf7edf2a-cf5d-4cdf-9446-b11fd5b63443"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47619047619047616"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import FloatType\n",
        "preds_and_labels = test_results.select(['prediction',\n",
        "                                       'label']).withColumn('label',\n",
        "                                                        F.col('label').cast(FloatType())).orderBy('prediction')\n",
        "\n",
        "#select only prediction and label columns\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
        "\n",
        "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
        "\n",
        "print(metrics.confusionMatrix().toArray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm8zho0UlDIh",
        "outputId": "a767b75e-72d1-46f4-a2cf-f04bb6ba82a0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8. 6.]\n",
            " [5. 2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_metric = MulticlassMetrics(test_results[\"label\",\"prediction\"].rdd)\n",
        "print(\"Accuracy\", lr_metric.accuracy)\n",
        "print(\"Precision\", lr_metric.precision(1.0))\n",
        "print(\"Recall\", lr_metric.recall(1.0))\n",
        "print(\"F1score\", lr_metric.fMeasure(1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdExjr-8lGTt",
        "outputId": "8b14bfd8-6090-4b09-ab8d-ef8210db9908"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.47619047619047616\n",
            "Precision 0.2857142857142857\n",
            "Recall 0.25\n",
            "F1score 0.26666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training,test=clean_data.randomSplit([0.7,0.3])"
      ],
      "metadata": {
        "id": "WxTjYkiDlI80"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag_detector = lr.fit(training)"
      ],
      "metadata": {
        "id": "jDmp0u2dlLG0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = flag_detector.transform(test)"
      ],
      "metadata": {
        "id": "HzGX-qhSlM4E"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### It predicts almost everything like 0\n",
        "test_results.show(80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQz0467elPPB",
        "outputId": "9c267a71-63ae-4483-bdea-2b4b44f2af2e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|label|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|  0.0|(661,[0,1,2,6,11,...|[9.70555159991846...|[0.99993905949772...|       0.0|\n",
            "|  0.0|(661,[0,3,8,36,48...|[-3.7637125660631...|[0.02267153620012...|       1.0|\n",
            "|  0.0|(661,[1,9,29,33,3...|[16.5887157106814...|[0.99999993753851...|       0.0|\n",
            "|  0.0|(661,[2,5,27,58,1...|[12.5436895764237...|[0.99999643267000...|       0.0|\n",
            "|  0.0|(661,[2,26,38,43,...|[13.4540786911899...|[0.99999856461883...|       0.0|\n",
            "|  0.0|(661,[3,13,30,36,...|[8.17808440885354...|[0.99971933958547...|       0.0|\n",
            "|  0.0|(661,[3,475,477,6...|[13.1610674676920...|[0.99999807593301...|       0.0|\n",
            "|  0.0|(661,[4,10,45,58,...|[18.2477098460134...|[0.99999998811168...|       0.0|\n",
            "|  0.0|(661,[5,20,28,179...|[10.4807512949252...|[0.99997192916346...|       0.0|\n",
            "|  0.0|(661,[5,23,108,18...|[14.5898316013969...|[0.99999953898352...|       0.0|\n",
            "|  0.0|(661,[9,15,19,20,...|[12.4555135914280...|[0.99999610383369...|       0.0|\n",
            "|  0.0|(661,[9,202,219,5...|[14.0951329410328...|[0.99999924393137...|       0.0|\n",
            "|  0.0|(661,[15,17,287,5...|[15.3102427208397...|[0.99999977569137...|       0.0|\n",
            "|  0.0|(661,[27,46,69,15...|[11.1085343016835...|[0.99998501632503...|       0.0|\n",
            "|  0.0|(661,[27,99,154,1...|[15.0633614974354...|[0.99999971287890...|       0.0|\n",
            "|  0.0|(661,[31,135,146,...|[9.64596606775983...|[0.99993531820370...|       0.0|\n",
            "|  0.0|(661,[81,95,569,6...|[15.6546214667870...|[0.99999984104133...|       0.0|\n",
            "|  0.0|(661,[124,659,660...|[8.13733689116644...|[0.99970767058655...|       0.0|\n",
            "|  0.0|(661,[244,659],[3...|[16.0565115899923...|[0.99999989364802...|       0.0|\n",
            "|  1.0|(661,[0,6,180,405...|[14.1598593627499...|[0.99999929131880...|       0.0|\n",
            "|  1.0|(661,[0,25,42,52,...|[7.28224937399667...|[0.99931283544998...|       0.0|\n",
            "|  1.0|(661,[0,37,73,107...|[8.54442479448364...|[0.99980541070552...|       0.0|\n",
            "|  1.0|(661,[1,2,5,6,11,...|[5.80467476937629...|[0.99699561885130...|       0.0|\n",
            "|  1.0|(661,[1,63,183,22...|[16.7983489745571...|[0.99999994935113...|       0.0|\n",
            "|  1.0|(661,[7,22,27,34,...|[2.27411833217165...|[0.90671072656127...|       0.0|\n",
            "|  1.0|(661,[15,41,108,1...|[8.87345578070360...|[0.99985996187186...|       0.0|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "acc_eval=MulticlassClassificationEvaluator()"
      ],
      "metadata": {
        "id": "g4S44nPslRHj"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = acc_eval.evaluate(test_results,{acc_eval.metricName: \"f1\"})"
      ],
      "metadata": {
        "id": "B1aK8cyMlTvk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwsAPBjVlVRv",
        "outputId": "ff01a2c4-66ad-4908-a9a9-f6bc1c932e9e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5979020979020979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator= MulticlassClassificationEvaluator()\n",
        "\n",
        "evaluator.setPredictionCol(\"prediction\")\n",
        "\n",
        "\n",
        "evaluator.evaluate(test_results)\n",
        "\n",
        "\n",
        "evaluator.evaluate(test_results, {evaluator.metricName: \"accuracy\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxK3Eo-hlW21",
        "outputId": "da0b3797-d3ef-4426-aa5d-bcd9cc856672"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6923076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import FloatType\n",
        "preds_and_labels = test_results.select(['prediction',\n",
        "                                       'label']).withColumn('label',\n",
        "                                                        F.col('label').cast(FloatType())).orderBy('prediction')\n",
        "\n",
        "#select only prediction and label columns\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
        "\n",
        "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
        "\n",
        "print(metrics.confusionMatrix().toArray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn1BkZAOlYvm",
        "outputId": "c79fca24-2d84-48a2-ebd5-9faa4b68d87e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18.  1.]\n",
            " [ 7.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_metric = MulticlassMetrics(test_results[\"label\",\"prediction\"].rdd)\n",
        "print(\"Accuracy\", lr_metric.accuracy)\n",
        "#print(\"Precision\", lr_metric.precision(1.0))\n",
        "#print(\"Recall\", lr_metric.recall(1.0))\n",
        "#print(\"F1score\", lr_metric.fMeasure(1.0))\n",
        "\n",
        "# Right now it throwed an error on Precision, Recall and F1score. Because the 0's from the previous cell \n",
        "# as you can see the Confusion Matrix throws two 0's on the second column, which means the model is predicting\n",
        "# everything as 0's in the model. If you run this code multiple time you will find that sometimes\n",
        "# it will predict everything as 0 or very few as 1. You can also use a seed. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtk9OYmIlazQ",
        "outputId": "1cbaebff-6c4d-499e-a5a5-be75cd3ddba2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.6923076923076923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FBXNB8mdldZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}